#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Script test Ä‘á»ƒ kiá»ƒm tra cáº£i tiáº¿n OCR
"""

import subprocess
from PIL import Image, ImageEnhance
import pytesseract
import numpy as np


def test_ocr():
    print("ğŸ” Kiá»ƒm tra cáº£i tiáº¿n OCR...")
    print("=" * 60)

    # Chá»¥p screenshot
    print("\n1ï¸âƒ£ Chá»¥p screenshot...")
    subprocess.run(
        "adb shell screencap -p /sdcard/screenshot.png", shell=True, check=True
    )
    subprocess.run(
        "adb pull /sdcard/screenshot.png /tmp/screenshot.png 2>/dev/null",
        shell=True,
        check=True,
    )
    print("âœ… ÄÃ£ chá»¥p screenshot")

    # Load image
    img = Image.open("/tmp/screenshot.png")
    width, height = img.size
    print(f"ğŸ“ KÃ­ch thÆ°á»›c: {width}x{height}px")

    # Crop vÃ¹ng OCR (70% pháº§n dÆ°á»›i)
    top = int(height * 0.7)
    img_crop = img.crop((0, top, width, height))
    print(f"âœ‚ï¸  ÄÃ£ crop vÃ¹ng OCR: (0,{top}) -> ({width},{height})")

    # Preprocessing
    print("\n2ï¸âƒ£ Preprocessing áº£nh...")

    # Grayscale
    img_gray = img_crop.convert("L")
    print("   âœ… Chuyá»ƒn sang grayscale")

    # TÄƒng contrast
    img_array = np.array(img_gray)
    img_array = np.clip(img_array * 1.2, 0, 255).astype(np.uint8)
    img_enhanced = Image.fromarray(img_array)
    print("   âœ… TÄƒng contrast")

    # Sharpen
    sharpener = ImageEnhance.Sharpness(img_enhanced)
    img_final = sharpener.enhance(2.0)
    print("   âœ… Sharpen")

    # LÆ°u áº£nh Ä‘á»ƒ xem
    img_final.save("/tmp/ocr_test_preprocessed.png")
    print(f"\nğŸ’¾ ÄÃ£ lÆ°u áº£nh preprocessing: /tmp/ocr_test_preprocessed.png")

    # Test vá»›i nhiá»u PSM modes
    print("\n3ï¸âƒ£ Thá»­ nhiá»u PSM modes...")
    print("=" * 60)

    psm_modes = [
        ("--oem 3 --psm 6", "Single uniform block"),
        ("--oem 3 --psm 11", "Sparse text"),
        ("--oem 3 --psm 3", "Fully automatic"),
    ]

    results = {}

    for config, desc in psm_modes:
        print(f"\nğŸ“ Mode: {desc} ({config})")
        try:
            text = pytesseract.image_to_string(img_final, lang="eng", config=config)
            results[desc] = text

            # Hiá»ƒn thá»‹ káº¿t quáº£
            print(f"   Text nháº­n Ä‘Æ°á»£c ({len(text)} chars):")
            print("   " + "-" * 56)
            for line in text.strip().split("\n")[:10]:  # Chá»‰ hiá»ƒn thá»‹ 10 dÃ²ng Ä‘áº§u
                print(f"   {line}")
            print("   " + "-" * 56)

            # Kiá»ƒm tra target texts
            target_texts = ["Test Flight Failure", "Dig Up Treasure"]
            found = []
            for target in target_texts:
                if target.lower() in text.lower():
                    found.append(target)

            if found:
                print(f"   âœ… TÃ¬m tháº¥y: {', '.join(found)}")
            else:
                print(f"   âŒ KhÃ´ng tÃ¬m tháº¥y target texts")

        except Exception as e:
            print(f"   âŒ Lá»—i: {e}")

    # So sÃ¡nh
    print("\n" + "=" * 60)
    print("ğŸ“Š Káº¾T QUáº¢ Tá»”NG Há»¢P:")
    print("=" * 60)

    for desc, text in results.items():
        target_texts = ["Test Flight Failure", "Dig Up Treasure"]
        found = [t for t in target_texts if t.lower() in text.lower()]

        status = "âœ…" if found else "âŒ"
        print(f"{status} {desc:30s} - TÃ¬m tháº¥y: {found if found else 'KhÃ´ng cÃ³'}")

    print("\nâœ¨ HoÃ n táº¥t kiá»ƒm tra!")
    print(f"ğŸ“ Xem áº£nh preprocessing táº¡i: /tmp/ocr_test_preprocessed.png")


if __name__ == "__main__":
    test_ocr()
